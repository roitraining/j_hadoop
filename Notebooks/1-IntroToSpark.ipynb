{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRjOMwVYiaET"
   },
   "source": [
    "### The Hadoop File System (HDFS) is a distributed file system that spans across multiple nodes and saves files in a cluster. It slices large files into blocks and redundantly saves multiple copies across several nodes in the cluster according to the replication factor chosen for the cluster. \n",
    "To examine the contents of the HDFS cluster, you either need to install the Hadoop tools on a local machine or ssh into a remote machine that has them installed.\n",
    "Try the following commands to see what is currently on the cluster and add new files to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQQ_mVrQiaEW"
   },
   "outputs": [],
   "source": [
    "! hadoop fs -ls /\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1g3fZTZiaEb"
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put /class/datasets/northwind/CSV/categories /\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2ZL2fi4iaEk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 items\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 20:24 /categories\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 17:01 /orders_part\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 16:55 /orders_table\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 17:34 /person\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 17:39 /person2\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 19:30 /region_avro\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 14:21 /regions\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 19:29 /regions_nested\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 16:08 /shippers4\n",
      "drwx-wx-wx   - root supergroup          0 2021-11-09 15:32 /tmp\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 16:50 /transactions\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 14:19 /user\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 15:48 /usstates11\n",
      "drwxr-xr-x   - root supergroup          0 2021-11-09 15:51 /usstates12\n",
      "Found 1 items\n",
      "-rw-r--r--   3 root supergroup        337 2021-11-09 20:24 /categories/categories.csv\n"
     ]
    }
   ],
   "source": [
    "! hadoop fs -ls /\n",
    "! hadoop fs -ls /categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stLlpheLWf_j"
   },
   "source": [
    "### Create the Spark context to start a session and connect to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oC4ujoSFWf_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing pyspark\n",
      "pyspark initialized\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/class')\n",
    "from initspark import *\n",
    "sc, spark, conf = initspark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH-N0vuoWf_v"
   },
   "source": [
    "### Read a text file from the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6iEi36CWf_w",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124796\n",
      "['The Project Gutenberg EBook of The Complete Works of William Shakespeare, by ', 'William Shakespeare', '', 'This eBook is for the use of anyone anywhere at no cost and with', 'almost no restrictions whatsoever.  You may copy it, give it away or', 're-use it under the terms of the Project Gutenberg License included', 'with this eBook or online at www.gutenberg.org', '', '** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **', '**     Please follow the copyright guidelines in this file.     **']\n"
     ]
    }
   ],
   "source": [
    "shake = sc.textFile('file:///class/datasets/text/shakespeare.txt')\n",
    "print(shake.count())\n",
    "print(shake.take(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['1,Beverages,Soft drinks coffees teas beers and ales', '2,Condiments,Sweet and savory sauces relishes spreads and seasonings', '3,Confections,Desserts candies and sweet breads', '4,Dairy Products,Cheeses', '5,Grains/Cereals,Breads crackers pasta and cereal', '6,Meat/Poultry,Prepared meats', '7,Produce,Dried fruit and bean curd', '8,Seafood,Seaweed and fish']\n"
     ]
    }
   ],
   "source": [
    "cat = sc.textFile('hdfs://localhost:9000/categories')\n",
    "#shake = sc.textFile('/categories')\n",
    "print(cat.count())\n",
    "print(cat.take(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `map` method can apply a function or lambda to each element of the collection, but distribute it to multiple workers to be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'EBook',\n",
       "  'of',\n",
       "  'The',\n",
       "  'Complete',\n",
       "  'Works',\n",
       "  'of',\n",
       "  'William',\n",
       "  'Shakespeare,',\n",
       "  'by',\n",
       "  ''],\n",
       " ['William', 'Shakespeare'],\n",
       " [''],\n",
       " ['This',\n",
       "  'eBook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with'],\n",
       " ['almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever.',\n",
       "  '',\n",
       "  'You',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it,',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or'],\n",
       " ['re-use',\n",
       "  'it',\n",
       "  'under',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'License',\n",
       "  'included'],\n",
       " ['with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org'],\n",
       " [''],\n",
       " ['**',\n",
       "  'This',\n",
       "  'is',\n",
       "  'a',\n",
       "  'COPYRIGHTED',\n",
       "  'Project',\n",
       "  'Gutenberg',\n",
       "  'eBook,',\n",
       "  'Details',\n",
       "  'Below',\n",
       "  '**'],\n",
       " ['**',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Please',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'copyright',\n",
       "  'guidelines',\n",
       "  'in',\n",
       "  'this',\n",
       "  'file.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '**']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake2 = shake.map(lambda x : x.split(' '))\n",
    "shake2.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdStyssVWgAU"
   },
   "source": [
    "### Parallelize will load manually created data into the spark cluster into an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XN8v44eNWgAW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "r = sc.parallelize(range(1,11))\n",
    "print(r.collect())\n",
    "print(r.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQVoJi3CWgAo"
   },
   "source": [
    "### Load a folder stored on HDFS or local and apply an function to each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tL89iGyOWgAq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,BEVERAGES,SOFT DRINKS COFFEES TEAS BEERS AND ALES', '2,CONDIMENTS,SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS', '3,CONFECTIONS,DESSERTS CANDIES AND SWEET BREADS', '4,DAIRY PRODUCTS,CHEESES', '5,GRAINS/CEREALS,BREADS CRACKERS PASTA AND CEREAL', '6,MEAT/POULTRY,PREPARED MEATS', '7,PRODUCE,DRIED FRUIT AND BEAN CURD', '8,SEAFOOD,SEAWEED AND FISH']\n",
      "PythonRDD[28] at collect at <ipython-input-10-15712c7b4bb1>:4\n"
     ]
    }
   ],
   "source": [
    "cat = sc.textFile('hdfs://localhost:9000/categories')\n",
    "cat = sc.textFile('file:///class/datasets/northwind/CSV/categories')\n",
    "cat = cat.map(lambda x : x.upper())\n",
    "print(cat.collect())\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlQ_B5enWgAz"
   },
   "source": [
    "### Try some different actions to fetch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCqmMuFLWgA1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,BEVERAGES,SOFT DRINKS COFFEES TEAS BEERS AND ALES', '2,CONDIMENTS,SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS', '3,CONFECTIONS,DESSERTS CANDIES AND SWEET BREADS', '4,DAIRY PRODUCTS,CHEESES', '5,GRAINS/CEREALS,BREADS CRACKERS PASTA AND CEREAL']\n",
      "['8,SEAFOOD,SEAWEED AND FISH', '7,PRODUCE,DRIED FRUIT AND BEAN CURD', '6,MEAT/POULTRY,PREPARED MEATS', '5,GRAINS/CEREALS,BREADS CRACKERS PASTA AND CEREAL', '4,DAIRY PRODUCTS,CHEESES']\n",
      "['6,MEAT/POULTRY,PREPARED MEATS', '4,DAIRY PRODUCTS,CHEESES', '1,BEVERAGES,SOFT DRINKS COFFEES TEAS BEERS AND ALES', '2,CONDIMENTS,SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS', '8,SEAFOOD,SEAWEED AND FISH']\n"
     ]
    }
   ],
   "source": [
    "print(cat.takeOrdered(5))\n",
    "print(cat.top(5))\n",
    "print(cat.takeSample(False,5))\n",
    "\n",
    "cat.foreach(lambda x : print(x.upper)) # does not display properly in notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqD-2-05WgBC"
   },
   "source": [
    "### Save the results in an RDD to disk. Note how it makes a folder and fills it with as many files as there are nodes solving the problem. Also, you must make sure that the folder does not exist or it throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au3L8fPDWgBE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/tmp/file1.txt': No such file or directory\n",
      "1,BEVERAGES,SOFT DRINKS COFFEES TEAS BEERS AND ALES\n",
      "2,CONDIMENTS,SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS\n",
      "3,CONFECTIONS,DESSERTS CANDIES AND SWEET BREADS\n",
      "4,DAIRY PRODUCTS,CHEESES\n",
      "5,GRAINS/CEREALS,BREADS CRACKERS PASTA AND CEREAL\n",
      "6,MEAT/POULTRY,PREPARED MEATS\n",
      "7,PRODUCE,DRIED FRUIT AND BEAN CURD\n",
      "8,SEAFOOD,SEAWEED AND FISH\n"
     ]
    }
   ],
   "source": [
    "! rm -r /tmp/file1.txt\n",
    "cat.saveAsTextFile('file:///tmp/file1.txt')\n",
    "! cat /tmp/file1.txt/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bt-1Pg9DWf_1"
   },
   "source": [
    "### Use the map method to apply a function call on each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3wwsvU6Wf_2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE PROJECT GUTENBERG EBOOK OF THE COMPLETE WORKS OF WILLIAM SHAKESPEARE, BY ',\n",
       " 'WILLIAM SHAKESPEARE',\n",
       " '',\n",
       " 'THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE AT NO COST AND WITH',\n",
       " 'ALMOST NO RESTRICTIONS WHATSOEVER.  YOU MAY COPY IT, GIVE IT AWAY OR',\n",
       " 'RE-USE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED',\n",
       " 'WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG',\n",
       " '',\n",
       " '** THIS IS A COPYRIGHTED PROJECT GUTENBERG EBOOK, DETAILS BELOW **',\n",
       " '**     PLEASE FOLLOW THE COPYRIGHT GUIDELINES IN THIS FILE.     **']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake2 = shake.map(str.upper)\n",
    "shake2.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qx0qMtPyWf_9"
   },
   "source": [
    "### Using the split method you get a list of lists. Apply a second map to change the lists to tuples and just keep the first two elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Szr74Z3AWf__"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'], ['2', 'CONDIMENTS', 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'], ['3', 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'], ['4', 'DAIRY PRODUCTS', 'CHEESES'], ['5', 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL']]\n",
      "[(1, 'BEVERAGES'), (2, 'CONDIMENTS'), (3, 'CONFECTIONS'), (4, 'DAIRY PRODUCTS'), (5, 'GRAINS/CEREALS')]\n"
     ]
    }
   ],
   "source": [
    "cat3 = cat.map(lambda x : x.split(','))\n",
    "print(cat3.take(5))\n",
    "\n",
    "cat3 = cat3.map(lambda x : (int(x[0]), x[1]))\n",
    "print(cat3.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `map` method returns a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124796 [['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare,', 'by', ''], ['William', 'Shakespeare'], [''], ['This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with'], ['almost', 'no', 'restrictions', 'whatsoever.', '', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or'], ['re-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included'], ['with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org'], [''], ['**', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook,', 'Details', 'Below', '**'], ['**', '', '', '', '', 'Please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file.', '', '', '', '', '**'], [''], ['Title:', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare'], [''], ['Author:', 'William', 'Shakespeare'], [''], ['Posting', 'Date:', 'September', '1,', '2011', '[EBook', '#100]'], ['Release', 'Date:', 'January,', '1994'], [''], ['Language:', 'English'], ['']]\n"
     ]
    }
   ],
   "source": [
    "shake3 = shake.map(lambda x : x.split(' '))\n",
    "print(shake3.count(), shake3.take(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-L0L9BiWgAF"
   },
   "source": [
    "### The `flatMap` method flattens the inner list to return one big list of strings instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP2oWr9CWgAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410759 ['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare,', 'by', '', 'William', 'Shakespeare', '', 'This', 'eBook', 'is', 'for']\n"
     ]
    }
   ],
   "source": [
    "shake4 = shake.flatMap(lambda x : x.split(' '))\n",
    "print(shake4.count(), shake4.take(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could map and existing function not just lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK88KrBTWgBN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,BEVERAGES,SOFT DRINKS COFFEES TEAS BEERS AND ALES', '2,CONDIMENTS,SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS', '3,CONFECTIONS,DESSERTS CANDIES AND SWEET BREADS', '4,DAIRY PRODUCTS,CHEESES', '5,GRAINS/CEREALS,BREADS CRACKERS PASTA AND CEREAL', '6,MEAT/POULTRY,PREPARED MEATS', '7,PRODUCE,DRIED FRUIT AND BEAN CURD', '8,SEAFOOD,SEAWEED AND FISH']\n"
     ]
    }
   ],
   "source": [
    "print(cat.map(str.upper).collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vn43ZGHWgBT"
   },
   "source": [
    "### Parse the string into a tuple to resemble a record structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ2bIehvWgBU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'),\n",
       " (2, 'CONDIMENTS', 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'),\n",
       " (3, 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'),\n",
       " (4, 'DAIRY PRODUCTS', 'CHEESES'),\n",
       " (5, 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL'),\n",
       " (6, 'MEAT/POULTRY', 'PREPARED MEATS'),\n",
       " (7, 'PRODUCE', 'DRIED FRUIT AND BEAN CURD'),\n",
       " (8, 'SEAFOOD', 'SEAWEED AND FISH')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1 = cat.map(lambda x : tuple(x.split(',')))\n",
    "cat1 = cat1.map(lambda x : (int(x[0]), x[1], x[2]))\n",
    "cat1.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ko12EKvYWgBX"
   },
   "source": [
    "## LAB: ## \n",
    "### Put the regions folder found in /class/datasets/northwind/CSV/regions into HDFS. Read it into an RDD and convert it into a tuple shape.\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use hadoop fs -put or hdfs dfs -put\n",
    "<br>\n",
    "Read the file using sc.textFile\n",
    "<br>\n",
    "Do a map to split and another to convert the datatypes\n",
    "<br>\n",
    "<br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "! hadoop fs -put /class/datasets/northwind/CSV/regions /regions\n",
    "regions = sc.textFile('hdfs://localhost:9000/regions')\n",
    "regions = regions.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
    "print(regions.collect())\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZWX8p7nWgBY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'Eastern'}, {'id': 2, 'name': 'Western'}, {'id': 3, 'name': 'Northern'}, {'id': 4, 'name': 'Southern'}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can create complex python functions to map onto elements instead of using simple lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'), (2, 'CONDIMENTS', 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'), (3, 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'), (4, 'DAIRY PRODUCTS', 'CHEESES'), (5, 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL'), (6, 'MEAT/POULTRY', 'PREPARED MEATS'), (7, 'PRODUCE', 'DRIED FRUIT AND BEAN CURD'), (8, 'SEAFOOD', 'SEAWEED AND FISH')]\n"
     ]
    }
   ],
   "source": [
    "def multicomma(x):\n",
    "    if len(x) == 2:\n",
    "        return (int(x[0]), x[1], 'Unknown')\n",
    "    elif len(x) == 3:\n",
    "        return (int(x[0]), x[1], x[2])\n",
    "    else:\n",
    "        return (None, None, None)\n",
    "        \n",
    "cat3 = cat.map(lambda x : x.split(',')).map(multicomma)\n",
    "print(cat3.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lc8uQPq1WgBi"
   },
   "source": [
    "### You can chain multiple transformations together to do it all in one step.\n",
    "#### Here we converted the datatypes to int, then turned the tuple into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLPu-glWgBj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CategoryID': 1,\n",
       "  'Name': 'BEVERAGES',\n",
       "  'Description': 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'},\n",
       " {'CategoryID': 2,\n",
       "  'Name': 'CONDIMENTS',\n",
       "  'Description': 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'},\n",
       " {'CategoryID': 3,\n",
       "  'Name': 'CONFECTIONS',\n",
       "  'Description': 'DESSERTS CANDIES AND SWEET BREADS'},\n",
       " {'CategoryID': 4, 'Name': 'DAIRY PRODUCTS', 'Description': 'CHEESES'},\n",
       " {'CategoryID': 5,\n",
       "  'Name': 'GRAINS/CEREALS',\n",
       "  'Description': 'BREADS CRACKERS PASTA AND CEREAL'},\n",
       " {'CategoryID': 6, 'Name': 'MEAT/POULTRY', 'Description': 'PREPARED MEATS'},\n",
       " {'CategoryID': 7,\n",
       "  'Name': 'PRODUCE',\n",
       "  'Description': 'DRIED FRUIT AND BEAN CURD'},\n",
       " {'CategoryID': 8, 'Name': 'SEAFOOD', 'Description': 'SEAWEED AND FISH'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2 = cat.map(lambda x : tuple(x.split(','))) \\\n",
    "      .map(lambda x : (int(x[0]), x[1], x[2])) \\\n",
    "      .map(lambda x : dict(zip(['CategoryID', 'Name', 'Description'], x)))\n",
    "cat2.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Could make a single function to do all the steps on each element and call a single `map` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'categoryid': 1,\n",
       "  'name': 'BEVERAGES',\n",
       "  'description': 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'},\n",
       " {'categoryid': 2,\n",
       "  'name': 'CONDIMENTS',\n",
       "  'description': 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'},\n",
       " {'categoryid': 3,\n",
       "  'name': 'CONFECTIONS',\n",
       "  'description': 'DESSERTS CANDIES AND SWEET BREADS'},\n",
       " {'categoryid': 4, 'name': 'DAIRY PRODUCTS', 'description': 'CHEESES'},\n",
       " {'categoryid': 5,\n",
       "  'name': 'GRAINS/CEREALS',\n",
       "  'description': 'BREADS CRACKERS PASTA AND CEREAL'},\n",
       " {'categoryid': 6, 'name': 'MEAT/POULTRY', 'description': 'PREPARED MEATS'},\n",
       " {'categoryid': 7,\n",
       "  'name': 'PRODUCE',\n",
       "  'description': 'DRIED FRUIT AND BEAN CURD'},\n",
       " {'categoryid': 8, 'name': 'SEAFOOD', 'description': 'SEAWEED AND FISH'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_cat(x):\n",
    "    step1 = x.split(',')\n",
    "    step2 = (int(step1[0]), step1[1], step1[2])\n",
    "    step3 = dict(zip(['categoryid', 'name', 'description'], step2))\n",
    "    return step3\n",
    "#cat.take(2)    \n",
    "cat.map(parse_cat).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1451bwFaWgBn"
   },
   "source": [
    "### The `filter` method takes a lambda that returns a True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQzyEYCYWgBo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CategoryID': 8, 'Name': 'SEAFOOD', 'Description': 'SEAWEED AND FISH'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cat2.filter(lambda x : x['CategoryID'] <= 5).collect()\n",
    "#cat2.filter(lambda x : x['CategoryID'] % 2 == 0).collect()\n",
    "cat2.filter(lambda x : x['Name'].startswith('S')).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22q9mGVrWgBu"
   },
   "source": [
    "### The `filter` expressions can be more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIEc83jgWgBw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CategoryID': 2,\n",
       "  'Name': 'CONDIMENTS',\n",
       "  'Description': 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'},\n",
       " {'CategoryID': 6, 'Name': 'MEAT/POULTRY', 'Description': 'PREPARED MEATS'},\n",
       " {'CategoryID': 8, 'Name': 'SEAFOOD', 'Description': 'SEAWEED AND FISH'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2.filter(lambda x : x['CategoryID'] % 2 == 0 and 'e' in x['Name'].lower()).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-mS0TT9WgB6"
   },
   "source": [
    "### The `sortBy` method returns an expression that is used to sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQwZ4Z_vWgB7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CategoryID': 1,\n",
       "  'Name': 'BEVERAGES',\n",
       "  'Description': 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'},\n",
       " {'CategoryID': 2,\n",
       "  'Name': 'CONDIMENTS',\n",
       "  'Description': 'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'},\n",
       " {'CategoryID': 3,\n",
       "  'Name': 'CONFECTIONS',\n",
       "  'Description': 'DESSERTS CANDIES AND SWEET BREADS'},\n",
       " {'CategoryID': 4, 'Name': 'DAIRY PRODUCTS', 'Description': 'CHEESES'},\n",
       " {'CategoryID': 5,\n",
       "  'Name': 'GRAINS/CEREALS',\n",
       "  'Description': 'BREADS CRACKERS PASTA AND CEREAL'},\n",
       " {'CategoryID': 6, 'Name': 'MEAT/POULTRY', 'Description': 'PREPARED MEATS'},\n",
       " {'CategoryID': 7,\n",
       "  'Name': 'PRODUCE',\n",
       "  'Description': 'DRIED FRUIT AND BEAN CURD'},\n",
       " {'CategoryID': 8, 'Name': 'SEAFOOD', 'Description': 'SEAWEED AND FISH'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2.sortBy(lambda x : x['Name']).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4gTRsTrWgCD"
   },
   "source": [
    "### `sortBy` has an option ascending parameter to sort in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRq5r1UAWgCF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8', 'SEAFOOD', 'SEAWEED AND FISH'],\n",
       " ['7', 'PRODUCE', 'DRIED FRUIT AND BEAN CURD'],\n",
       " ['6', 'MEAT/POULTRY', 'PREPARED MEATS'],\n",
       " ['5', 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL'],\n",
       " ['4', 'DAIRY PRODUCTS', 'CHEESES'],\n",
       " ['3', 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'],\n",
       " ['2',\n",
       "  'CONDIMENTS',\n",
       "  'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'],\n",
       " ['1', 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1 = cat.map(lambda x : x.split(','))\n",
    "cat1.sortBy(lambda x : x[0], ascending = False).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r40EeKuEWgCK"
   },
   "source": [
    "## LAB:##\n",
    "### Try to sort region in descending order by ID and then by name in ascending order. ###\n",
    "\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use sortByKey and sortBy respectively\n",
    "<br>\n",
    "sortBy needs a lambda\n",
    "<br><br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "print(regions.sortByKey(ascending = False).collect())\n",
    "print(regions.sortBy(lambda x : x[1]).collect())\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eF5E8yZyWgCL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'],\n",
       " ['2',\n",
       "  'CONDIMENTS',\n",
       "  'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'],\n",
       " ['3', 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'],\n",
       " ['4', 'DAIRY PRODUCTS', 'CHEESES'],\n",
       " ['5', 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL'],\n",
       " ['6', 'MEAT/POULTRY', 'PREPARED MEATS'],\n",
       " ['7', 'PRODUCE', 'DRIED FRUIT AND BEAN CURD'],\n",
       " ['8', 'SEAFOOD', 'SEAWEED AND FISH']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to be aware of the shape of the data. Some function require data to be shaped into just two elements, a key and a value. So the value portion may be more complex than just one simple value. We often need to reshape complex data into a simple two element tuple as a preparatory step for another function.\n",
    "\n",
    "```\n",
    "# (1, 'A', 'B')\n",
    "# (2, 'C', 'D')  3 elements per row\n",
    "# (1, 'E', 'F')\n",
    "\n",
    "# reshape to just 2 elements (Key, everything else)\n",
    "# (1, ('A','B'))\n",
    "# (2, ('C','D')) 2 elements per row 1 Key, 2 everything else wrapped up in a tuple or dict\n",
    "# (1, ('E','F'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4e5XbSMWgCO"
   },
   "source": [
    "### Reshape categories from a tuple of three elements like (1, 'Beverages', 'Soft drinks') to a tuple with two elements (key, value) like (1, ('Beverages', 'Soft drinks'))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yu2izny5WgCP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BEVERAGES', ['1', 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES']),\n",
       " ('CONDIMENTS',\n",
       "  ['2',\n",
       "   'CONDIMENTS',\n",
       "   'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS']),\n",
       " ('CONFECTIONS', ['3', 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS']),\n",
       " ('DAIRY PRODUCTS', ['4', 'DAIRY PRODUCTS', 'CHEESES']),\n",
       " ('GRAINS/CEREALS',\n",
       "  ['5', 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL']),\n",
       " ('MEAT/POULTRY', ['6', 'MEAT/POULTRY', 'PREPARED MEATS']),\n",
       " ('PRODUCE', ['7', 'PRODUCE', 'DRIED FRUIT AND BEAN CURD']),\n",
       " ('SEAFOOD', ['8', 'SEAFOOD', 'SEAWEED AND FISH'])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat3 = cat1.map(lambda x : (x[0], (x[1], x[2]))) # eliminate the key from the values collection\n",
    "cat3 = cat1.map(lambda x : (x[1], x)) # keep the key in the values collection\n",
    "cat3.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ge3v9g1NWgCR"
   },
   "source": [
    "### The sortByKey method does not require a function as a parameter if the data is structured into a tuple of the shape (key, value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MF6jtxiKWgCS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'BEVERAGES', 'SOFT DRINKS COFFEES TEAS BEERS AND ALES'],\n",
       " ['2',\n",
       "  'CONDIMENTS',\n",
       "  'SWEET AND SAVORY SAUCES RELISHES SPREADS AND SEASONINGS'],\n",
       " ['3', 'CONFECTIONS', 'DESSERTS CANDIES AND SWEET BREADS'],\n",
       " ['4', 'DAIRY PRODUCTS', 'CHEESES'],\n",
       " ['5', 'GRAINS/CEREALS', 'BREADS CRACKERS PASTA AND CEREAL'],\n",
       " ['6', 'MEAT/POULTRY', 'PREPARED MEATS'],\n",
       " ['7', 'PRODUCE', 'DRIED FRUIT AND BEAN CURD'],\n",
       " ['8', 'SEAFOOD', 'SEAWEED AND FISH']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cat3.sortByKey(ascending=False).collect()\n",
    "#cat3.sortByKey(ascending=False).map(lambda x : x[1] ).collect()\n",
    "cat1.map(lambda x: (x[1], x)).sortByKey().map(lambda x : x[1]).collect()\n",
    "\n",
    "\n",
    "\n",
    "# select col1, count(col2) \n",
    "#from table\n",
    "#where col3 =3 \n",
    "#group by col1\n",
    "with step1 as\n",
    "(select col1, col2 from table where col3 = 3)\n",
    "select col1, count(col2) from step1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ubk9dpCWWgCX"
   },
   "source": [
    "### Read in another CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dprx0Q-_WgCY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1,Chai,8,1,10 boxes x 30 bags,18.0,39,0,10,1',\n",
       " '2,Chang,1,1,24 - 12 oz bottles,19.0,17,40,25,1',\n",
       " '3,Aniseed Syrup,1,2,12 - 550 ml bottles,10.0,13,70,25,0',\n",
       " \"4,Chef Anton's Cajun Seasoning,2,2,48 - 6 oz jars,22.0,53,0,0,0\"]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = sc.textFile('file:///class/datasets/northwind/CSV/products')\n",
    "print(prod.count())\n",
    "prod.take(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtLTEKPgWgCb"
   },
   "source": [
    "### Split it up and just keep the ProductID, ProductName, CategoryID, Price, Quantity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAEwAdJUWgCc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Chai', 1, 18.0, 39),\n",
       " (2, 'Chang', 1, 19.0, 17),\n",
       " (3, 'Aniseed Syrup', 2, 10.0, 13),\n",
       " (4, \"Chef Anton's Cajun Seasoning\", 2, 22.0, 53),\n",
       " (5, \"Chef Anton's Gumbo Mix\", 2, 21.35, 0)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prod1 = prod.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1], int(x[3]), float(x[5]), int(x[6])))\n",
    "prod1 = (sc.textFile('file:///class/datasets/northwind/CSV/products')\n",
    "          .map(lambda x : x.split(','))\n",
    "          .map(lambda x : (int(x[0]), x[1], int(x[3]), float(x[5]), int(x[6])))\n",
    "        )\n",
    "prod1.take(5)\n",
    "\n",
    "# FROM filename\n",
    "# SELECT ....\n",
    "# SELECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "962IynkWWgCg"
   },
   "source": [
    "### Reshape it to a key value tuple where category is the key and the other fields are the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIP64lugWgCh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (1, 'Chai', 18.0, 39)),\n",
       " (1, (2, 'Chang', 19.0, 17)),\n",
       " (2, (3, 'Aniseed Syrup', 10.0, 13)),\n",
       " (2, (4, \"Chef Anton's Cajun Seasoning\", 22.0, 53)),\n",
       " (2, (5, \"Chef Anton's Gumbo Mix\", 21.35, 0))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod2 = prod1.map(lambda x : (x[2], (x[0], x[1], x[3], x[4])))\n",
    "prod2.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1hNliYJWgCl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Beverages'),\n",
       " (2, 'Condiments'),\n",
       " (3, 'Confections'),\n",
       " (4, 'Dairy Products'),\n",
       " (5, 'Grains/Cereals'),\n",
       " (6, 'Meat/Poultry'),\n",
       " (7, 'Produce'),\n",
       " (8, 'Seafood')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cat1.collect()\n",
    "cat2 = cat1.map(lambda x : (int(x[0]), x[1].title()))\n",
    "cat2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aS2NAAXHWgCo"
   },
   "source": [
    "### Both c3 and prod2 are in key value tuple format so they can be joined to produce a new tuple of (key, (cat, prod))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZmbDZCGWgCp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('Beverages', (1, 'Chai', 18.0, 39))),\n",
       " (1, ('Beverages', (2, 'Chang', 19.0, 17))),\n",
       " (1, ('Beverages', (24, 'Guarana Fantastica', 4.5, 20))),\n",
       " (1, ('Beverages', (34, 'Sasquatch Ale', 14.0, 111))),\n",
       " (1, ('Beverages', (35, 'Steeleye Stout', 18.0, 20))),\n",
       " (1, ('Beverages', (38, 'Cote de Blaye', 263.5, 17))),\n",
       " (1, ('Beverages', (39, 'Chartreuse verte', 18.0, 69))),\n",
       " (1, ('Beverages', (43, 'Ipoh Coffee', 46.0, 17))),\n",
       " (1, ('Beverages', (67, 'Laughing Lumberjack Lager', 14.0, 52))),\n",
       " (1, ('Beverages', (70, 'Outback Lager', 15.0, 15))),\n",
       " (1, ('Beverages', (75, 'Rhonbrau Klosterbier', 7.75, 125))),\n",
       " (1, ('Beverages', (76, 'Lakkalikoori', 18.0, 57))),\n",
       " (2, ('Condiments', (3, 'Aniseed Syrup', 10.0, 13))),\n",
       " (2, ('Condiments', (4, \"Chef Anton's Cajun Seasoning\", 22.0, 53))),\n",
       " (2, ('Condiments', (5, \"Chef Anton's Gumbo Mix\", 21.35, 0)))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = cat2.join(prod2)\n",
    "joined.sortByKey().take(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OI8VffUbWgCt"
   },
   "source": [
    "## LAB: ##\n",
    "### Load territories into HDFS and join it to regions. ###\n",
    "\n",
    "\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Put /class/datasets/northwind/CSV/territories into HDFS\n",
    "<br>\n",
    "Use sc.textFile to read it into an RDD\n",
    "<br>\n",
    "Use map to split and convert it to the proper datatypes\n",
    "<br>\n",
    "Use the join method\n",
    "<br><br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "! hadoop fs -put /class/datasets/northwind/CSV/territories /\n",
    "\n",
    "territories = sc.textFile('hdfs://localhost:9000/territories')\n",
    "territories = territories.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1], int(x[2])))\n",
    "print(territories.collect())\n",
    "\n",
    "region_territories = regions.join(territories.map(lambda x : (x[2], (x[0],x[1]))))\n",
    "print(region_territories.collect())\n",
    "# Reshape it to make it look more normal. The * in front of the x is a python unpacking trick\n",
    "region_territories = region_territories.map(lambda x : (x[0], (x[1][0], *x[1][1])))\n",
    "print(region_territories.collect())\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG-jz9oCWgCu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S7_N8D4vWgCy"
   },
   "source": [
    "### The groupBy methods are seldom used but they can produce hierarchies where children records are embedded inside a parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8XG_Zh1WgC5"
   },
   "outputs": [],
   "source": [
    "group1 = prod2.groupByKey()\n",
    "group1.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlfoIOfvWgCz"
   },
   "outputs": [],
   "source": [
    "list(group1.take(1)[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mi73ZFk4WgC_"
   },
   "outputs": [],
   "source": [
    "group2 = [(key, list(it)) for key, it in group1.collect()]\n",
    "for k,v in group2:\n",
    "    print ('Key:', k)\n",
    "    for x in v:\n",
    "        print(x)\n",
    "#print (group2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiQFuV5bWgDF"
   },
   "source": [
    "### The reduce methods take a function as a parameter that tells Spark how to accumulate the values for each group. The function takes two parameters; the first is the accumulated value and the second is the next value in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FCNryN_WgDG"
   },
   "outputs": [],
   "source": [
    "shake4.map(lambda x : (x, 1)).reduceByKey(lambda x, y : x + y).sortBy(lambda x : x[1], ascending = False).take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agTxvAFjWgDK"
   },
   "source": [
    "## LAB: ## \n",
    "### Use the territories RDD to count how many territories are in each region. \n",
    "### Display the results in regionID order and then descending order based on the counts.\n",
    "<br>\n",
    "<details><summary>Click for <b>hint</b></summary>\n",
    "<p>\n",
    "Use map to put the key first then reduceByKey to accumulate the values\n",
    "<br>\n",
    "Use sortByKey to sort by regionID and sortBy with a lambda to sort by counts\n",
    "<br><br>\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary>Click for <b>code</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "region_count = territories.map(lambda x : (x[2], 1)).reduceByKey(lambda x, y: x + y)\n",
    "print(region_count.sortByKey().collect())\n",
    "print(region_count.sortBy(lambda x : x[1], ascending = False).collect())\n",
    "```\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PF1xAAZVWgDL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GejVQTZMWgDP"
   },
   "source": [
    "### In this example, we are adding up all the prices for each categoryID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTQCEouBWgDQ"
   },
   "outputs": [],
   "source": [
    "red1 = prod2.map(lambda x : (x[0], x[1][2])).reduceByKey(lambda x, y: x + y)\n",
    "red1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FH_hY2_PWgDV"
   },
   "source": [
    "### To accumulate more than one value, use a tuple to hold as many values as you want to aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtQX34KiWgDW"
   },
   "outputs": [],
   "source": [
    "red1 = prod2.map(lambda x : (x[0], (x[1][2], x[1][3], 1))).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "red1.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-e6do4WZWgDg"
   },
   "source": [
    "### Some Python magic can make things easier in the long run.\n",
    "Named tuples make accessing the elements of the row easier.\n",
    "Unpacking using the * is a neat Python trick that is widely used.\n",
    " \n",
    "datetime has function to convert a string into a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoiIjU2wWgDl"
   },
   "outputs": [],
   "source": [
    "mort = sc.textFile('file:///class/datasets/finance/30YearMortgage.csv')\n",
    "head = mort.first()\n",
    "mort = mort.filter(lambda x : x != head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fyvY687WgDp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from collections import namedtuple\n",
    "Rate = namedtuple('Rate','date fed_fund_rate avg_rate_30year')\n",
    "mort1 = mort.map(lambda x : Rate(*(x.split(','))))\n",
    "mort2 = mort1.map(lambda x : Rate(datetime.strptime(x.date, '%Y-%m').date(), float(x.fed_fund_rate), float(x.avg_rate_30year)))\n",
    "mort2.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4i7WOKwIWgDt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mort2.filter(lambda x : x.fed_fund_rate > .1 ).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjXdMjdxWgDw"
   },
   "source": [
    "### HOMEWORK:\n",
    "1. The creditcard.csv dataset provides sample data on credit card transactions\n",
    "2. Load the file into HDFS\n",
    "3. Load the file into an RDD\n",
    "4. Parse the file into a tuple or namedtuple or dictionary\n",
    "5. Make sure to convert columns to the right data types\n",
    "6. You can ignore any columns you donâ€™t need for the solution\n",
    "7. Filter the data to show only transactions made by women\n",
    "8. Calculate the amount spent in each city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQNAL1_xWgDx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day1-IntroToSpark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
