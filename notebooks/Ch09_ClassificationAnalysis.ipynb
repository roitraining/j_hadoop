{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch09_ClassificationAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roitraining/jpmc_hadoop/blob/master/notebooks/Ch09_ClassificationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVESJgGmrOnE",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "rootpath = '/class/'\n",
        "datapath = f'{rootpath}datasets/'\n",
        "sys.path.append(rootpath)\n",
        "import pyspark_helpers as pyh\n",
        "from pyspark_helpers import *\n",
        "sc, spark, conf = initspark()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pyspark_helpers import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjQW-P4nKXG1",
        "colab_type": "text"
      },
      "source": [
        "### Let's read in a bank data set to try to predict if a potential borrower will default on their loan before lending to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xOtG6pXJrOnN",
        "colab": {}
      },
      "source": [
        "filename = 'bank.csv'\n",
        "df = spark.read.csv(f'{datapath}/finance/{filename}', header = True, inferSchema = True)\n",
        "display(df)\n",
        "\n",
        "# Save a pointer to the raw data\n",
        "dfRawFile = df\n",
        "print(df.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLr829zIKXG8",
        "colab_type": "text"
      },
      "source": [
        "### Clean up the dataset by identifying the numeric and categorical features and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-FZqXtsrOnR",
        "colab": {}
      },
      "source": [
        "# Let's just keep a few fields to start with for simplicity\n",
        "import imp\n",
        "imp.reload(pyh)\n",
        "\n",
        "num = pyh.auto_numeric_features(df, exceptlist = ('day'))\n",
        "print (num)\n",
        "cat = pyh.auto_categorical_features(df, suffix = None, exceptlist = ('default'))\n",
        "#cat = pyh.auto_categorical_features(df, suffix = ('ing', 'ion'))\n",
        "print (cat)\n",
        "\n",
        "numeric_features = ['age','balance', 'duration', 'pdays']\n",
        "categorical_features = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'campaign', 'poutcome', 'deposit']\n",
        "\n",
        "# numeric_features = ['balance', 'duration', 'age']\n",
        "# categorical_features = ['marital', 'education']\n",
        "target_label = 'default'\n",
        "\n",
        "\n",
        "df = dfRawFile.select(numeric_features + categorical_features + [target_label])\n",
        "display(df)\n",
        "print(df.take(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "27HGsZ6ArOnW"
      },
      "source": [
        "### Explore numeric features to see if there is any correlation between values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMFO0oVOrOnY",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#display(df.describe())\n",
        "display(pyh.describe_numeric_features(df, numeric_features))\n",
        "pyh.scatter_matrix(df, numeric_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ3zCaMcKXHG",
        "colab_type": "text"
      },
      "source": [
        "### Use the helper function to reshape it for ML training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CtWabts7rOnc",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# import imp\n",
        "# imp.reload(pyh)\n",
        "dfML.cache()\n",
        "dfML, keydict = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label = 'default', target_is_categorical=True, return_key_dict = True)\n",
        "display(dfML)\n",
        "dfML.printSchema()\n",
        "labelCnt = dfML.groupBy('label').count()\n",
        "display(labelCnt)\n",
        "print('keydict ' , keydict)\n",
        "print(dfML.take(1))\n",
        "print(df.take(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xw_RBw9xrOnf",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "labelCnt.toPandas().plot(kind = 'bar')\n",
        "df.groupBy('job').count().toPandas().plot(kind='bar')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWPePk31KXHP",
        "colab_type": "text"
      },
      "source": [
        "### Save the Vectorized file in case we want to use it again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4AevDiyFrOnp",
        "colab": {}
      },
      "source": [
        "dfML.write.format('parquet').mode('overwrite').save('testsave')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exXVAYA4KXHV",
        "colab_type": "text"
      },
      "source": [
        "### Reload it to see it worked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqyr75eVKXHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfML0 = spark.read.format('parquet').load('testsave')\n",
        "dfML0.printSchema()\n",
        "display(dfML0)\n",
        "dfML = dfML0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVG04IlyKXHa",
        "colab_type": "text"
      },
      "source": [
        "### Split it into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJ5WvSOErOnt",
        "colab": {}
      },
      "source": [
        "#dfML = dfML0\n",
        "train, test = dfML.randomSplit([.7,.3], seed = 100)\n",
        "print (f'Training set row count {train.count()}')\n",
        "print (f'Testing set row count {test.count()}')\n",
        "display(train.groupBy('label').count())\n",
        "display(test.groupBy('label').count())\n",
        "#print(test.take(1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXrn3t5LKXHe",
        "colab_type": "text"
      },
      "source": [
        "### Import the Decision Tree classifier and train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnOwIT8_rOnw",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 6)\n",
        "dtModel = dt.fit(train)\n",
        "print('DT Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_DT_trainedModel'\n",
        "dtModel.write().overwrite().save(filename1)\n",
        "print('DT Saved')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSHj5Dk2KXHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassificationModel\n",
        "dtModel = DecisionTreeClassificationModel.load(filename1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nkS5GJoKXHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = dtModel.transform(test)\n",
        "display(pred)\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "metrics = MulticlassMetrics(pred.select(['label', 'prediction']).rdd.map(lambda line: (line[1], line[0])))\n",
        "print(metrics.confusionMatrix().toArray())\n",
        "dir(metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHlsZSasKXHq",
        "colab_type": "text"
      },
      "source": [
        "### Normally, there are a lot of steps to predict and test. We have built a helper function to bundle all that up.\n",
        "Take a look at the source code for it to see those indivual steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EByE2E-WrOn0",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "dtPredictions, dtLog = pyh.predict_and_evaluate(dtModel, test, show=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWAZkMWbKXHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dtLog)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM3SF_6xKXHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(df)\n",
        "rdd = df.rdd\n",
        "print(type(df), type(rdd))\n",
        "print(df.take(1))\n",
        "print(rdd.take(1))\n",
        "\n",
        "print(dir(df))\n",
        "print ('*' * 50)\n",
        "print(dir(rdd))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fufaLfb0KXH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtLog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDr6ZJLgKXH7",
        "colab_type": "text"
      },
      "source": [
        "### Now let's try Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "goWOCubRrOn5",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
        "lrModel = lr.fit(train)\n",
        "print('LR Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_LR_trainedModel'\n",
        "lrModel.write().overwrite().save(filename1)\n",
        "print('LR Saved')\n",
        "\n",
        "#evaluate_model(lr)\n",
        "pyh.beta_coefficients(lrModel)\n",
        "pyh.roc_curve(lrModel)\n",
        "pyh.precision_recall(lrModel)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVPv5t1irOn9",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegressionModel\n",
        "lrModel2 = LogisticRegressionModel.load(filename1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hsm3w5BKXIL",
        "colab_type": "text"
      },
      "source": [
        "### See the test results as before, but LR has some extra options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGB_IDUUrOoB",
        "colab": {}
      },
      "source": [
        "print(lrModel.summary.roc)\n",
        "lrPredictions, lrLog = pyh.predict_and_evaluate(lrModel, test, showModel = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0ps78_JKXIS",
        "colab_type": "text"
      },
      "source": [
        "### Let's try different thresholds to see if we can tweak the false positive/negative balance or improve the overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEUZW4tKXIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr2 = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, threshold = .1).fit(train)\n",
        "\n",
        "#lr2Predictions, lr2Log = pyh.predict_and_evaluate(lr2, test, showModel = False)\n",
        "\n",
        "display(lr2Predictions.select('probability'))\n",
        "lr2Predictions.printSchema()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_JMmO2aKXIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import expr, udf\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "print(lr2Predictions.select('probability').take(2))\n",
        "#print(lr2Predictions.where('probability[0] >= .2 and probability <= .8').select('probability').take(2))\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "\n",
        "spark.udf.register('firstelement', lambda v:float(v[0]), FloatType())\n",
        "\n",
        "lr2Predictions.createOrReplaceTempView('predictions')\n",
        "display(spark.sql('select probability from predictions where firstelement(probability) between .2 and .8'))\n",
        "\n",
        "firstelement=udf(lambda v:float(v[0]),FloatType())\n",
        "#lr2Predictions.select(firstelement('probability')).show()\n",
        "lr2Predictions.where(firstelement('probability') >= .2).where(firstelement('probability') <= .8 ).select('probability').show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s198ZdlLKXIc",
        "colab_type": "text"
      },
      "source": [
        "### After a while it's the same thing over and over, but try out as many models as possible to see which works best.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XoN-fiT2rOoE",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label', numTrees = 20, maxDepth = 3)\n",
        "rfModel = rf.fit(train)\n",
        "print('RF Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_RF_trainedModel'\n",
        "rfModel.write().overwrite().save(filename1)\n",
        "print('RF Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aF0GSzKXrOoK",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "rfPredictions, rfLog = pyh.predict_and_evaluate(rfModel, test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gzdWEgUKXIn",
        "colab_type": "text"
      },
      "source": [
        "### Try Gradient Boost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90o6tiojrOoO",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "gbt = GBTClassifier(maxIter=10)\n",
        "gbtModel = gbt.fit(train)\n",
        "print ('GBT Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_GBT_trainedModel'\n",
        "rfModel.write().overwrite().save(filename1)\n",
        "print ('GBT Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wuna45UTrOoR",
        "colab": {}
      },
      "source": [
        "gbtPredictions, gbtLog = pyh.predict_and_evaluate(gbtModel, test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LRk83r6KXIx",
        "colab_type": "text"
      },
      "source": [
        "### Try Neural Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6QPLoCu1rOoV",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 13 (features), two intermediate of size 5 and 4\n",
        "# and output of size 2 (classes)\n",
        "layers = [13, 5, 4, 2]\n",
        "\n",
        "nn = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "nnModel = nn.fit(train)\n",
        "print ('NN Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_NN_trainedModel'\n",
        "nnModel.write().overwrite().save(filename1)\n",
        "print ('NN Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyGelMkDKXI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnPredictions = nnModel.transform(test)\n",
        "#pyh.evaluate_ROC(nnPredictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blt7nlLJrOoe",
        "colab": {}
      },
      "source": [
        "nnPredictions = nnModel.transform(test)\n",
        "print(type(nnPredictions))\n",
        "#print(nnPredictions.take(1))\n",
        "nnPredictions.printSchema()\n",
        "print (nnPredictions.count())\n",
        "\n",
        "#nnPredictions, nnLog = pyh.predict_and_evaluate(nnModel, test)\n",
        "##nnPredictions.take(1)\n",
        "predictionAndLabels = nnPredictions.select(\"prediction\", \"label\")\n",
        "#display(predictionAndLabels)\n",
        "#print(predictionAndLabels.collect())\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAwZ4rc6KXJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one(x):\n",
        "    print(x)\n",
        "    return x\n",
        "\n",
        "def two(x):\n",
        "    print(x*2)\n",
        "    return x * 2\n",
        "\n",
        "def three(x):\n",
        "    print(x*3)\n",
        "    return x * 3\n",
        "\n",
        "a = 4\n",
        "b = 10\n",
        "if a == 0:\n",
        "    one(b)\n",
        "elif a == 1:\n",
        "    two(b)\n",
        "else:\n",
        "    three(b)\n",
        "    \n",
        "    \n",
        "opts = {0: one\n",
        "        , 1: two\n",
        "        , 4: lambda x : x * 10\n",
        "       }\n",
        "opts.get(a, three)(b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EiZnj3adrOot",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "#     , (MultilayerPerceptronClassifier, dict(maxIter=100, layers=[13, 5, 4, 2], blockSize=128, seed=1234))\n",
        "#     , (MultilayerPerceptronClassifier, dict(maxIter=100, layers=[13, 3, 2], blockSize=128, seed=1234))\n",
        "\n",
        "models = [\n",
        "    (DecisionTreeClassifier, dict(featuresCol = 'features', labelCol = 'label', maxDepth = 6))\n",
        "    , (DecisionTreeClassifier, dict(featuresCol = 'features', labelCol = 'label', maxDepth = 3))\n",
        "    , (RandomForestClassifier, dict(featuresCol = 'features', labelCol = 'label', numTrees = 20, maxDepth = 3))\n",
        "    , (GBTClassifier, {})\n",
        "]\n",
        "\n",
        "for modelclass, params in models:\n",
        "    model = modelclass(**params)\n",
        "    trained = model.fit(train)\n",
        "    #pred = trained.transform(test)\n",
        "    pred, log = pyh.predict_and_evaluate(trained, test, showModel = False, show = False)\n",
        "    print (log)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wcuSS4eKXJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
